{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3bdc023",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44d3e88f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80667, 20)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/processed/filtered_complaints.csv\")\n",
    "\n",
    "df = df.dropna(subset=[\"clean_narrative\"]).reset_index(drop=True)\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aed924ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Optional: limit dataset size with stratified sampling\n",
    "sample_size = 15000  # or 10000\n",
    "df_sampled, _ = train_test_split(\n",
    "    df,\n",
    "    train_size=sample_size,\n",
    "    stratify=df[\"Product\"],  # ensures balanced distribution across products\n",
    "    random_state=42\n",
    ")\n",
    "df = df_sampled.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b129c821",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_text(text, chunk_size=300, overlap=50):\n",
    "    words = text.split()\n",
    "    chunks = []\n",
    "\n",
    "    for i in range(0, len(words), chunk_size - overlap):\n",
    "        chunk = words[i:i + chunk_size]\n",
    "        chunks.append(\" \".join(chunk))\n",
    "\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58c8dca2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20731"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_chunks = []\n",
    "metadata = []\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    chunks = chunk_text(row[\"clean_narrative\"])\n",
    "\n",
    "    for chunk in chunks:\n",
    "        all_chunks.append(chunk)\n",
    "        metadata.append({\n",
    "            \"Complaint ID\": row[\"Complaint ID\"],\n",
    "            \"Product\": row[\"Product\"]\n",
    "        })\n",
    "\n",
    "len(all_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f4a4caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6a97c69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6018d83005754849849d87e59ab22795",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/648 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(20731, 384)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = model.encode(\n",
    "    all_chunks,\n",
    "    show_progress_bar=True,\n",
    "    convert_to_numpy=True\n",
    ")\n",
    "\n",
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "effba4e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20731"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dimension = embeddings.shape[1]\n",
    "\n",
    "index = faiss.IndexFlatL2(dimension)\n",
    "index.add(embeddings)\n",
    "\n",
    "index.ntotal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f52fe46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "vector_dir = \"data/vector_store\"\n",
    "os.makedirs(vector_dir, exist_ok=True)\n",
    "\n",
    "# Save FAISS index\n",
    "faiss.write_index(index, os.path.join(vector_dir, \"complaints_faiss.index\"))\n",
    "\n",
    "# Save metadata\n",
    "pd.DataFrame(metadata).to_csv(\n",
    "    os.path.join(vector_dir, \"complaints_metadata.csv\"),\n",
    "    index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0d218ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "faiss.write_index(index, \"../data/complaints_faiss.index\")\n",
    "\n",
    "pd.DataFrame(metadata).to_csv(\n",
    "    \"../data/complaints_metadata.csv\",\n",
    "    index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "56b38fa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my card was charged for a total of xxxx dollars which i did n t authorize american express didnt srefund my money \n",
      "\n",
      "the bank opened an annual fee credit card without my permission \n",
      "\n",
      "i signed up for a xxxx xxxxr card with first progress xx xx year the card has a 29 00 annual fee after activation i never activated the card i never received any statements i recently obtained a copy  \n",
      "\n",
      "a credit card from barclaysxxxx xxxx account was opened in my name without my knowledge or consent i did not apply for this credit card and i did not authorize any charges on it i discovered the accou \n",
      "\n",
      "the credit card added intrest to my credit card bill for no reason and my bill was past due all because of that and they wont take the late fee and interest off my bill \n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"credit card charged fees I did not authorize\"\n",
    "\n",
    "query_embedding = model.encode([query])\n",
    "distances, indices = index.search(query_embedding, k=5)\n",
    "\n",
    "for i in indices[0]:\n",
    "    print(all_chunks[i][:200], \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
